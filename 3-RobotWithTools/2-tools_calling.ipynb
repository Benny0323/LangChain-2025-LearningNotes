{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "åœ¨è®²åˆ° tool calling è¿™ä¸€ä¸ªæ¦‚å¿µä»¥å‰ï¼Œéœ€è¦æå‰äº†è§£æ˜¯ä»€ä¹ˆæ˜¯ `Function calling`ã€‚è¿™æ˜¯ä¸€ä¸ªåœ¨ OpenAI çš„[å®˜æ–¹æ–‡æ¡£](https://platform.openai.com/docs/guides/function-calling/example-use-cases?api-mode=responses)ä¸­æå‡ºçš„æ¦‚å¿µã€‚ç®€å•æ¥è¯´ï¼Œ`Function Calling` æ˜¯æŒ‡å¤§è¯­è¨€æ¨¡å‹åœ¨ç†è§£ç”¨æˆ·è¾“å…¥åï¼Œè‡ªåŠ¨é€‰æ‹©è¦è°ƒç”¨çš„å‡½æ•°ï¼Œå¹¶å¡«å……è°ƒç”¨å‚æ•°ï¼Œç„¶åç­‰å¾…å¤–éƒ¨ç³»ç»Ÿè°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼Œå†æŠŠç»“æœä¼ å›æ¨¡å‹ç»§ç»­å¯¹è¯æˆ–å›ç­”ã€‚\n",
    "\n",
    "å…·ä½“è€Œè¨€ï¼Œæœ‰ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\n",
    "1. å¯¹å‡½æ•°è¿›è¡Œå®šä¹‰ã€‚å°±å¦‚åŒ 3-1 è®²çš„é‚£æ ·ï¼Œéœ€è¦å®šä¹‰ä¸€ä¸ª toolï¼ŒåŒ…å«ç€ä¸€å®šçš„ schemaï¼Œå‘ LLM å£°æ˜å¯ä»¥ä½¿ç”¨çš„å·¥å…·ï¼Œä¾‹å¦‚æœ‰ä¸ªè·å–åˆ°å¤©æ°”æ•°æ®çš„ toolï¼š\n",
    "```json\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the weather for a given city.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the city\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "2. ç”¨æˆ·è¿›è¡Œæé—®ï¼š\n",
    "```json\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Whatâ€™s the weather like in Paris today?\"}\n",
    "]\n",
    "```\n",
    "\n",
    "3. ç”± LLM è‡ªåŠ¨å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨é¢å¤–çš„ toolï¼Œä»¥åŠä½¿ç”¨å“ªä¸€ä¸ª tool\n",
    "```json\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"content\": null,\n",
    "  \"function_call\": {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"arguments\": \"{ \\\"location\\\": \\\"Paris\\\" }\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "æ­¤æ—¶ LLM éœ€è¦ tool (`get_weather`) å»æŸ¥è¯¢å¤©æ°”æƒ…å†µï¼Œæ‰èƒ½å›ç­”æˆ‘ä»¬å¤©æ°”åˆ°åº•æ€ä¹ˆæ ·ã€‚\n",
    "\n",
    "4. åç«¯ï¼ˆå¼€å‘è€…ï¼‰æ ¹æ® LLM éœ€è¦çš„å‡½æ•°åã€å‚æ•°å»è°ƒç”¨å‡½æ•°ï¼Œå®Œæˆ function callingï¼š\n",
    "```python\n",
    "# LLM æŒ‡æ˜äº†éœ€è¦è¿™ä¸ªå‡½æ•°\n",
    "def get_weather(location):\n",
    "    \"\"\"Fetching the weather data from some websites...\"\"\"\n",
    "    return f\"The weather in {location} is XXXXXX.\"\n",
    "\n",
    "# LLM æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ç›®æ ‡ï¼Œå‘å‡½æ•°ä¸­ä¼ å…¥ \"Paris\" è¿™ä¸ªå‚æ•°\n",
    "tool_result = get_weather(\"Paris\")\n",
    "```\n",
    "å½“åç«¯è·å–åˆ°çœŸå®çš„æ•°æ®ä¹‹åï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶ä½œä¸ºä¿¡æ¯ä¼ å…¥ LLM ä¸­ï¼š\n",
    "```python\n",
    "messages.append({\n",
    "    \"role\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"content\": \"The weather in Paris is sunny.\"\n",
    "})\n",
    "```\n",
    "\n",
    "5. LLM æ¥æ”¶åˆ°äº† role ä¸º \"function\" çš„æ¶ˆæ¯ï¼ˆåŒ…å«ç€å¤©æ°”ä¿¡æ¯ï¼‰ï¼Œæ­¤æ—¶æ ¹æ® messages å†…å®¹ LLM å°±å¯ä»¥å›ç­”ä½ å¤©æ°”å…·ä½“æ€ä¹ˆæ ·äº†ã€‚\n",
    "\n",
    "\n"
   ],
   "id": "d18af22cec0d95c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T19:51:43.002633Z",
     "start_time": "2025-04-06T19:51:42.944901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# è€æ ·å­ï¼Œå¯¼å…¥æˆ‘ä»¬çš„é…ç½®æ–‡ä»¶å’Œ API Key\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,  # æ­¤æ—¶éœ€è¦æˆ‘ä»¬çš„ LLM æ›´ä¸¥è°¨\n",
    "    max_tokens=2048,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ],
   "id": "107b209762cd98b8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "LangChain ä¸­çš„ tool callingæµç¨‹ï¼š\n",
    "![Tool Calling Workflow](https://python.langchain.com/assets/images/tool_calling_components-bef9d2bcb9d3706c2fe58b57bf8ccb60.png)\n",
    "1. å·¥å…·åˆ›å»ºï¼šä½¿ç”¨ @tool æ³¨è§£ï¼Œå¹¶è¯¦ç»†åœ¨ description ä¸­è§£é‡Šå·¥å…·çš„ç”¨æ³•\n",
    "2. å·¥å…·ç»‘å®šï¼šæŠŠå·¥å…·ç»‘å®šåœ¨æ”¯æŒ tool calling çš„ LLM ä¸Š\n",
    "3. å·¥å…·è°ƒç”¨ï¼šå¦‚æœ LLM å†³å®šæ—¶æœºå·²åˆ°ï¼Œä¼šè°ƒç”¨æŸä¸€é¡¹å·¥å…·å¹¶ç¡®ä¿è¾“å…¥è¾“å‡ºç¬¦åˆå·¥å…·çš„å®šä¹‰\n",
    "4. å·¥å…·æ‰§è¡Œï¼šLLM æä¾›å‚æ•°ï¼Œç”± tool å‡½æ•°å»è¿”å› LLM æ‰€éœ€çš„ç»“æœ"
   ],
   "id": "ddb2d5fdaa550f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "æ¥ä¸‹æ¥æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå…·ä½“çš„å·¥å…·ã€‚æˆ‘ä»¬éƒ½çŸ¥é“ LLMï¼ˆå°¤å…¶æ˜¯ GPT-3.5-turboï¼‰åœ¨å›ç­” \"9.11 å’Œ 9.9 å“ªä¸€ä¸ªæ›´å¤§ï¼Ÿ\" è¿™ç±»é—®é¢˜æ—¶çŠ¯é”™ã€‚ä¸ºäº†ä¸å®ƒå‡ºé”™ï¼Œæˆ‘ä»¬äº²æ‰‹è®¾è®¡ä¸€ä¸ª Comparison å‡½æ•°ï¼Œè®© LLM è§åˆ°è¿™ç±»é—®é¢˜çš„æ—¶å€™èƒ½å¤Ÿæƒ³èµ·æ¥ç”¨ä¸€ç”¨æˆ‘ä»¬çš„ toolï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªæ­£ç¡®çš„ç»“æœã€‚",
   "id": "d46b78d5e2e5b627"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:20:23.374637Z",
     "start_time": "2025-04-06T20:20:22.974541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# æˆ‘ä»¬å…ˆé—®é—®çœ‹ GPT-3.5 è¿™ä¸ªé—®é¢˜çš„ç»“æœ\n",
    "\n",
    "query = \"9.11 å’Œ 9.9 å“ªä¸€ä¸ªæ›´å¤§ï¼Ÿ\"\n",
    "message = [\n",
    "    HumanMessage(content=query)\n",
    "]\n",
    "response = llm.invoke(message)\n",
    "print(response.content)"
   ],
   "id": "13b0fc6540dcf83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 æ›´å¤§ã€‚\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ä¸å‡ºæ‰€æœ›ï¼ŒLLM åœ¨ä½¿ç”¨è¯­è¨€æ¨¡å‹æ¯”è¾ƒæ•°å€¼é—®é¢˜çš„æ—¶å€™ä¼šçŠ¯é”™ã€‚æˆ‘ä»¬æ¥ä¸‹æ¥åˆ›å»ºä¸€ä¸ª tool æ¥è®© LLM ä½¿ç”¨ã€‚",
   "id": "6969269027245ff9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:20:24.686593Z",
     "start_time": "2025-04-06T20:20:24.676801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def compare(a: float, b: float) -> float:\n",
    "    \"\"\"Compare two float number, a anb b\n",
    "    If a >= b, then return a;\n",
    "    Else if a < b, the return b.\n",
    "    \"\"\"\n",
    "    return a if a >= b else b\n",
    "\n",
    "# æˆ‘ä»¬å…ˆå°è¯•ä¸€ä¸‹è‡ªå·±æ‰‹åŠ¨è°ƒç”¨\n",
    "compare.invoke({\"a\": 9.11, \"b\": 9.9})"
   ],
   "id": "9492181f965ee349",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:20:25.754593Z",
     "start_time": "2025-04-06T20:20:25.337305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# æˆ‘ä»¬ä½¿ç”¨ bind_tool() æ–¹æ³•æ¥ç»‘å®šå·¥å…·\n",
    "llm_with_tools = llm.bind_tools([\n",
    "    compare\n",
    "])\n",
    "\n",
    "response = llm_with_tools.invoke(message)\n",
    "print(response.content)"
   ],
   "id": "d712f47c1db8b5ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Waitï¼Œä¸ºä»€ä¹ˆ LLM ç”¨äº†å·¥å…·ä¹‹åæ²¡æœ‰è¿”å›ç»“æœï¼Ÿç»“æœæ˜¯ç©ºçš„ï¼Ÿ",
   "id": "ce6fe51a492294d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:20:27.590723Z",
     "start_time": "2025-04-06T20:20:27.586813Z"
    }
   },
   "cell_type": "code",
   "source": "response.tool_calls",
   "id": "6fa32c7ec7f8a363",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'compare',\n",
       "  'args': {'a': 9.11, 'b': 9.9},\n",
       "  'id': 'call_Grj2J8cR5SMxAXDPr7ShtyMt',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "å¯ä»¥çœ‹è§ LLM ç¡®å®ç†è§£äº†æˆ‘ä»¬ç»™å®ƒçš„å·¥å…·ï¼Œå¹¶ä¸”å®ƒä¹Ÿæ‰“ç®—è°ƒç”¨ã€‚ä½†æ˜¯ LLM æ²¡åŠæ³•ä½¿ç”¨è¿™ä¸ªå‡½æ•°ï¼ˆå› ä¸ºè¿™ä¸ªå‡½æ•°åœ¨æœ¬åœ°ï¼Œæˆ‘ä»¬åªç»™å®ƒäº†è¿™ä¸ªå‡½æ•°çš„ç”¨æ³•ï¼‰ï¼Œå®ƒåœ¨ç­‰å¾…æˆ‘ä»¬åç«¯è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼Œå¹¶æŠŠç»“æœè¿”å›ç»™å®ƒã€‚",
   "id": "8c74b81cd913a9a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:20:29.418629Z",
     "start_time": "2025-04-06T20:20:28.856626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "first_response = response\n",
    "\n",
    "# æŠŠ assistant å›å¤ï¼ˆå« tool_callsï¼‰ä¹ŸåŠ å…¥ message ä¸­ï¼Œåªæœ‰è¿™æ ·æˆ‘ä»¬ LLM æ‰èƒ½çŸ¥é“æˆ‘ä»¬ tool è¿”å›çš„ç»“æœæ˜¯å›ç­”å“ªä¸€ä¸ªé—®é¢˜çš„\n",
    "message.append(first_response)\n",
    "\n",
    "# æ‹¿åˆ°å·¥å…·è°ƒç”¨è¯·æ±‚\n",
    "tool_call = first_response.tool_calls[0]\n",
    "tool_name = tool_call['name']\n",
    "tool_args = tool_call['args']\n",
    "\n",
    "# ç„¶åæˆ‘ä»¬è‡ªå·±æ‰§è¡Œå·¥å…· compare()\n",
    "tool_result = compare.invoke(tool_args)\n",
    "\n",
    "# æˆ‘ä»¬æŠŠå·¥å…·è¿”å›çš„ç»“æœå‰åæ–‡åŠ å…¥åˆ°ä¸‹ä¸€æ¬¡ message ä¸­\n",
    "message.append(\n",
    "    ToolMessage(tool_call_id=tool_call['id'], content=str(tool_result))\n",
    ")\n",
    "\n",
    "# æœ€åä¸€æ­¥ï¼šå†æ¬¡è°ƒç”¨ LLMï¼Œè·å–æœ€ç»ˆç­”æ¡ˆ\n",
    "final_response = llm_with_tools.invoke(message)\n",
    "print(final_response.content)"
   ],
   "id": "820f2e81e68a6c1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 å’Œ 9.9 ä¸­ï¼Œ9.9 æ›´å¤§ã€‚\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "OKï¼Œæ­¤æ—¶æˆ‘ä»¬å®Œæˆäº† tool calling çš„ä¸€ä¸ªç®€å•ç”¨æ³•ã€‚ä½†æ˜¯æœ‰ä¸ªå°é—®é¢˜ï¼Œå‡è®¾æˆ‘ä»¬ tool å·¥å…·ç±»é€æ¸å¢å¤šï¼Œä½œä¸ºå¼€å‘äººå‘˜çš„æˆ‘ä»¬æ²¡æ³•è®°ä½é‚£ä¹ˆå¤š tool çš„ç”¨æ³•ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å…¶å®æ˜¯æ ¹æ® `tool_name = tool_call['name']` çš„ç»“æœï¼ˆå…¶å®å°±æ˜¯ `compare`ï¼‰ï¼Œå»æ‰‹åŠ¨è°ƒç”¨ `tool_result = compare.invoke(tool_args)` å‡½æ•°çš„ã€‚\n",
    "\n",
    "ğŸ¤” æˆ‘ä»¬æ€è€ƒä¸€ä¸‹èƒ½å¦ä½¿ç”¨ç±»ä¼¼äº Java çš„ Spring Boot ä¸­çš„åå°„æœºåˆ¶ï¼ˆè™½ç„¶å¹¶é Spring ç‰¹æœ‰ï¼‰ï¼Œè®©åç«¯è‡ªåŠ¨çš„æ ¹æ®è¿”å›çš„ `tool_name` å»æ‰¾åˆ°å¯¹åº”çš„å·¥å…·å‘¢ï¼Ÿ\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨LangChain æˆ– OpenAI Function Calling çš„â€œè‡ªåŠ¨ Tool è·¯ç”±å™¨â€æœºåˆ¶ï¼Œæ¥è‡ªåŠ¨è°ƒç”¨å‡½æ•°ã€‚\n",
    "> æ—§ç‰ˆæœ¬æ˜¯ç”¨ `ToolExecutor`ï¼Œæ ¹æ® `tool_name` è‡ªåŠ¨åŒ¹é…ä½ æ³¨å†Œçš„å·¥å…·å¹¶æ‰§è¡Œã€‚\n",
    ">\n",
    "> æ–°ç‰ˆæœ¬æˆ‘ä»¬ä½¿ç”¨ LangChain `AgentExecutor`ã€‚å®ƒæ˜¯ä¸€ä¸ªæ›´é«˜çº§çš„å°è£…ï¼Œè‡ªåŠ¨å®Œæˆä»¥ä¸‹æµç¨‹ï¼š\n",
    "> 1. è®©æ¨¡å‹å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·\n",
    "> 2. è‡ªåŠ¨æ‰§è¡Œå·¥å…·ï¼ˆæ— éœ€ä½ è‡ªå·± .invoke(...)ï¼‰\n",
    "> 3. æŠŠå·¥å…·æ‰§è¡Œç»“æœä¼ å›æ¨¡å‹\n",
    "> 4. è®©æ¨¡å‹ç»§ç»­ç”Ÿæˆæœ€ç»ˆå›å¤"
   ],
   "id": "70c7d194efeee81b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:37:17.535695Z",
     "start_time": "2025-04-06T20:37:15.928638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "\n",
    "# 1. å®šä¹‰ä½ çš„å·¥å…·\n",
    "tools = [compare]\n",
    "\n",
    "# 2. ã€å¿…éœ€ã€‘æ–°ç‰ˆæœ¬éœ€è¦æ˜¾å¼ä¼ å…¥ä¸€ä¸ª ChatPromptTemplateï¼Œä¸èƒ½è‡ªåŠ¨ç”Ÿæˆé»˜è®¤ prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªæ“…é•¿è°ƒç”¨å·¥å…·çš„åŠ©æ‰‹\"),\n",
    "    # MessagesPlaceholder(variable_name=\"chat_history\"), <-- æ³¨é‡Šæ‰è¿™ä¸ªå³æ²¡æœ‰ä¸Šä¸‹æ–‡è®°å¿†ï¼Œä¸è¿‡å¯¹äºå½“å‰é—®é¢˜æ²¡æœ‰å½±å“ã€‚è§£é™¤æ³¨é‡Šä¼šæŠ¥é”™ï¼Œå› ä¸ºæ²¡æœ‰ chat_history\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# 3. åˆ›å»º Agentï¼ˆä½¿ç”¨ OpenAI Function Calling æ¨¡å¼ï¼‰\n",
    "agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# 4. åˆ›å»º executorï¼ˆè‡ªåŠ¨å®Œæˆè°ƒç”¨/æ‰§è¡Œ/å›åº”ï¼‰\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "\n",
    "# 5. ä¸€å¥è¯è°ƒç”¨ï¼Œè‡ªåŠ¨å®Œæˆæ‰€æœ‰æµç¨‹\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": \"è¯·æ¯”è¾ƒ 9.11 å’Œ 9.9 å“ªä¸ªæ›´å¤§ï¼Ÿ\"}\n",
    ")\n",
    "\n",
    "print(response[\"output\"])"
   ],
   "id": "2aeb882e28128edc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.9 æ¯” 9.11 æ›´å¤§ã€‚\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Agent çš„çŸ¥è¯†æˆ‘ä»¬ä¼šåœ¨åé¢å†ä»”ç»†ç ”ç©¶ï¼Œè¿™é‡Œåªå½“åšä½“éªŒä¸€ä¸‹æ›´é«˜çº§çš„ LangChain æµç¨‹ã€‚",
   "id": "902732dd5c1257d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
